{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_events(df):\n",
    "    \n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    df['day'] = df['start_time'].dt.day\n",
    "\n",
    "    df_merged = df.merge(df, how='inner', on=['year', 'month', 'day'])\n",
    "    df_merged = df_merged[df_merged['src_x'] != df_merged['src_y']]\n",
    "\n",
    "    l = df_merged['src_x'] + df_merged['id_x'].astype(str)\n",
    "    r = df_merged['src_y'] + df_merged['id_y'].astype(str)\n",
    "    df_merged['id'] = np.where(l < r, l + r, r + l)\n",
    "\n",
    "    df_merged.drop_duplicates(subset='id', inplace=True)    \n",
    "     \n",
    "    return df_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels(df_merged, random_state=0, balanced=True):\n",
    "    \n",
    "    df_merged['target'] = 0\n",
    "\n",
    "    condition = 'place_names'\n",
    "    mask = (df_merged['place_name_x'].str.lower() == df_merged['place_name_y'].str.lower()) & (df_merged['place_name_x'] !='') & (df_merged['start_time_x'] == df_merged['start_time_y'])\n",
    "    df_merged.loc[mask, 'target'] = 1\n",
    "    df_merged.loc[mask, 'condition'] = condition\n",
    "\n",
    "    condition = 'names'\n",
    "    mask = df_merged['name_x'].str.lower() == df_merged['name_y'].str.lower()\n",
    "    df_merged.loc[mask, 'target'] = 1\n",
    "    df_merged.loc[mask, 'condition'] = condition\n",
    "\n",
    "    condition = 'facebook_id'\n",
    "    mask = df_merged['facebook_id_x'] == df_merged['facebook_id_y']\n",
    "    df_merged.loc[mask, 'target'] = 1\n",
    "    df_merged.loc[mask, 'condition'] = condition\n",
    "\n",
    "    if balanced:\n",
    "        n = np.sum(df_merged['target'])\n",
    "        df_merged = df_merged[df_merged['target'] == 1].append(df_merged[df_merged['target'] == 0].sample(n=n, random_state=random_state), sort = False)\n",
    "\n",
    "    return df_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(name_x, name_y, description_x, description_y, start_time_x, start_time_y, place_name_x, place_name_y, street_x, street_y):\n",
    "    from nltk.metrics import edit_distance\n",
    "    \n",
    "    X = {}\n",
    "    \n",
    "    name_x = name_x.lower()\n",
    "    name_y = name_y.lower()    \n",
    "    place_name_x = place_name_x.lower()\n",
    "    place_name_y = place_name_y.lower()\n",
    "    street_x = street_x.lower()\n",
    "    street_y = street_y.lower()\n",
    "\n",
    "    X['time_diff'] = abs((start_time_x - start_time_y).total_seconds() / 3600)\n",
    "    X['coll_sim'] = 2 * len([1 for collocation in re.findall(r'([A-Z]+\\w*\\.? [A-Z]+\\w+)', description_x) if collocation in description_y]) / (1 + len(re.findall(r'([A-Z]+\\w*\\.? [A-Z]+\\w+)', description_x)) + len(re.findall(r'([A-Z]+\\w*\\.? [A-Z]+\\w+)', description_y)))\n",
    "\n",
    "    X['name_equality'] = name_x == name_y\n",
    "    X['name_intersect'] = name_x in name_y or name_y in name_x\n",
    "    X['name_levensthein'] = edit_distance(name_x,name_y)\n",
    "    X['name_common_words'] = 2 * len(set(name_x.split()).intersection(name_y.split())) / (len(name_x.split()) + len(name_y.split()))    \n",
    "    tri_name_x = [name_x[i:i+3] for i in range(len(name_x)-2)]\n",
    "    tri_name_y = [name_y[i:i+3] for i in range(len(name_y)-2)]\n",
    "    X['name_trigrams'] = 2 * len(set(tri_name_x).intersection(tri_name_y)) / (len(tri_name_x) + len(tri_name_y))    \n",
    "    first_letters_name_x = [i[0] for i in name_x.split()]\n",
    "    first_letters_name_y = [i[0] for i in name_y.split()]\n",
    "    X['name_first_letters'] = 2 * len(set(first_letters_name_x).intersection(first_letters_name_y)) / (len(first_letters_name_x) + len(first_letters_name_y))\n",
    "\n",
    "    tri_place_name_x = [place_name_x[i:i+3] for i in range(len(place_name_x)-2)]\n",
    "    tri_place_name_y = [place_name_y[i:i+3] for i in range(len(place_name_y)-2)]\n",
    "    X['place_name_trigrams'] = 2 * len(set(tri_place_name_x).intersection(tri_place_name_y)) / (len(tri_place_name_x) + len(tri_place_name_y))\n",
    "    first_letters_place_name_x = [i[0] for i in place_name_x.split()]\n",
    "    first_letters_place_name_y = [i[0] for i in place_name_y.split()]\n",
    "    X['place_name_first_letters'] = 2 * len(set(first_letters_place_name_x).intersection(first_letters_place_name_y)) / (len(first_letters_place_name_x) + len(first_letters_place_name_y))\n",
    "    \n",
    "    tri_street_x = [street_x[i:i+3] for i in range(len(street_x)-2)]\n",
    "    tri_street_y = [street_y[i:i+3] for i in range(len(street_y)-2)]\n",
    "    X['street_trigrams'] = 2 * len(set(tri_street_x).intersection(tri_street_y)) / (1 + len(tri_street_x) + len(tri_street_y))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deserializacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = joblib.load('../pickles/fb.pkl')\n",
    "ss = joblib.load('../pickles/ss.pkl')\n",
    "cjg = joblib.load('../pickles/cjg.pkl')\n",
    "sk = joblib.load('../pickles/sk.pkl')\n",
    "um = joblib.load('../pickles/um.pkl')\n",
    "concatenation = joblib.load('../pickles/concatenation.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kombinacja eventów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = combine_events(concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utworzenie zioru uczącego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = generate_labels(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_pairs.apply(lambda x: generate_features(x.name_x, x.name_y, x.description_x, x.description_y, x.start_time_x, x.start_time_y, x.place_name_x, x.place_name_y, x.street_x, x.street_y), axis=1)\n",
    "X = pd.DataFrame(X.tolist())\n",
    "y = train_pairs['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100, max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Train: %f, test: %f' % (clf.score(X_train, y_train),clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metryki modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':X.columns,'importance':np.round(clf.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "importances.plot.bar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Przetrenowanie modelu i serializacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, '../models/events_pairs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wygenerowanie cech dla wszystkich kombinacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combination.apply(lambda x: generate_features(x.name_x, x.name_y, x.description_x, x.description_y, x.start_time_x, x.start_time_y, x.place_name_x, x.place_name_y, x.street_x, x.street_y), axis=1)\n",
    "X = pd.DataFrame(X.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializacja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(X, '../pickles/X.pkl')\n",
    "#X = joblib.load('../pickles/X.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination['pred'] = clf.predict(X)\n",
    "combination['pred_prob'] = clf.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(combination['pred_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = combination[combination['pred'] == 1]\n",
    "pairs = pairs.sort_values('pred_prob', ascending=False).groupby(['src_x', 'src_y', 'id_x']).head(1)\n",
    "pairs = pairs.sort_values('pred_prob', ascending=False).groupby(['src_x', 'src_y', 'id_y']).head(1)\n",
    "pairs['src_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = combination[combination['pred'] == 1]\n",
    "pairs = pairs.sort_values('pred_prob', ascending=False).groupby(['src_x', 'src_y', 'id_x']).head(1)\n",
    "pairs = pairs.sort_values('pred_prob', ascending=False).groupby(['src_x', 'src_y', 'id_y']).head(1)\n",
    "pairs['src_x'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zapisanie par do pliku oraz  serializacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[['id_x', 'facebook_id_x', 'place_name_x', 'street_x', 'start_time_x',\n",
    "       'name_x', 'description_x', 'src_x','id_y', 'facebook_id_y', 'place_name_y',\n",
    "       'street_y', 'start_time_y', 'name_y', 'description_y', 'src_y','pred_prob']]\\\n",
    ".sort_values(by='pred_prob', ascending=False).to_csv('../output/pairs.csv', sep=',', float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pairs, '../pickles/pairs.pkl')\n",
    "joblib.dump(combination, '../pickles/combination.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_id = pairs[['id_x','id_y','src_x','src_y']].astype(str)\n",
    "df_tmp = fb[['fb']]\n",
    "concatenation['id'] = concatenation['id'].astype(str)\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "sources = ['fb','ss','cjg','sk','um']\n",
    "for pair in combinations(sources,2):\n",
    "    df_tmp = df_tmp.merge(pairs_id[(pairs_id['src_x'] == pair[0]) & (pairs_id['src_y'] == pair[1])].rename(columns = {'id_x': pair[0], 'id_y': pair[1]})[[pair[0], pair[1]]], how = 'outer')\n",
    "    \n",
    "for src in sources:\n",
    "    t = concatenation[concatenation['src'] == src][['id', 'facebook_id','place_name', 'street', 'start_time', 'name', 'description','lat','lng']]\n",
    "    df_tmp = df_tmp.merge(t, how='outer', left_on=src, right_on='id', suffixes=['','_' + src])\n",
    "    \n",
    "df_tmp['place_name_std'] = df_tmp['place_name']\n",
    "df_tmp['street_std'] = df_tmp['street']\n",
    "df_tmp['lat_std'] = df_tmp['lat']\n",
    "df_tmp['lng_std'] = df_tmp['lng']\n",
    "\n",
    "for src in sources[1:]:\n",
    "    df_tmp['place_name_std'] = df_tmp['place_name_std'].fillna(df_tmp['place_name_' + src])\n",
    "    df_tmp['street_std'] = df_tmp['street_std'].fillna(df_tmp['street_' + src])\n",
    "    df_tmp['lat_std'] = df_tmp['lat_std'].fillna(df_tmp['lat_' + src])\n",
    "    df_tmp['lng_std'] = df_tmp['lng_std'].fillna(df_tmp['lng_' + src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[['fb','ss','cjg','sk','um','facebook_id','id_cjg', 'id_sk', 'id_ss', 'id_um',\n",
    "       'name','name_ss','name_cjg','name_sk','name_um',\n",
    "       'place_name','place_name_ss','place_name_cjg','place_name_sk','place_name_um',\n",
    "       'street','street_ss','street_cjg','street_sk','street_um',\n",
    "       'start_time','start_time_ss','start_time_cjg','start_time_sk','start_time_um',\n",
    "       'description','description_ss','description_cjg','description_sk','description_um',\n",
    "       'place_name_std','street_std','lat_std','lng_std']].to_csv('../output/events_database.csv')\n",
    "\n",
    "joblib.dump(df_tmp, '../pickles/events_database.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
