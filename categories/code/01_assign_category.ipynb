{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "\n",
    "from auxiliaries import ColumnSelector\n",
    "from auxiliaries import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('../pickles/events_database.pkl')\n",
    "google_places = joblib.load('../pickles/google_places_flatten.pkl')\n",
    "events_tags = pd.read_csv('../data/events-tag_table_events_tags.csv')\n",
    "events_tags_rel = pd.read_csv('../data/events-tag_table_events_tags_rel.csv')\n",
    "organisers = pd.read_csv('../data/events-tag_table_organisers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dowiązanie informacji o typie miejsca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_places.rename(columns={'place_name': 'place_name_std'}, inplace=True)\n",
    "google_places['types'] = google_places['types'].astype(str)\n",
    "data = data.merge(google_places[['place_name_std','types']].drop_duplicates(), left_on='place_name_std', right_on='place_name_std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dowiązanie tagów do wydarzeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_events = data[['facebook_id', 'name', 'place_name_std', 'description', 'street_std', 'types']].dropna()\n",
    "fb_events['facebook_id'] = fb_events['facebook_id'].astype(int)\n",
    "events_tagged = fb_events.merge(events_tags_rel, left_on='facebook_id', right_on='event_facebook_id').merge(events_tags, left_on='event_tag_id', right_on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Budowa modelu do określania przestrzeni wydarzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = events_tagged[events_tagged['category'] == 'PRZESTRZEŃ WYDARZENIA'][['tagname','description','name','place_name_std', 'types']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "stop_words = ['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'ależ', 'ani', 'aż', 'bardziej', 'bardzo', 'bo', 'bowiem', 'by', 'byli', 'bynajmniej', 'być', 'był', 'była', 'było', 'były', 'będzie', 'będą', 'cali', 'cała', 'cały', 'ci', 'cię', 'ciebie', 'co', 'cokolwiek', 'coś', 'czasami', 'czasem', 'czemu', 'czy', 'czyli', 'daleko', 'dla', 'dlaczego', 'dlatego', 'do', 'dobrze', 'dokąd', 'dość', 'dużo', 'dwa', 'dwaj', 'dwie', 'dwoje', 'dziś', 'dzisiaj', 'gdy', 'gdyby', 'gdyż', 'gdzie', 'gdziekolwiek', 'gdzieś', 'i', 'ich', 'ile', 'im', 'inna', 'inne', 'inny', 'innych', 'iż', 'ja', 'ją', 'jak', 'jaka', 'jakaś', 'jakby', 'jaki', 'jakichś', 'jakie', 'jakiś', 'jakiż', 'jakkolwiek', 'jako', 'jakoś', 'je', 'jeden', 'jedna', 'jedno', 'jednak', 'jednakże', 'jego', 'jej', 'jemu', 'jest', 'jestem', 'jeszcze', 'jeśli', 'jeżeli', 'już', 'ją', 'każdy', 'kiedy', 'kilka', 'kimś', 'kto', 'ktokolwiek', 'ktoś', 'która', 'które', 'którego', 'której', 'który', 'których', 'którym', 'którzy', 'ku', 'lat', 'lecz', 'lub', 'ma', 'mają', 'mało', 'mam', 'mi', 'mimo', 'między', 'mną', 'mnie', 'mogą', 'moi', 'moim', 'moja', 'moje', 'może', 'możliwe', 'można', 'mój', 'mu', 'musi', 'my', 'na', 'nad', 'nam', 'nami', 'nas', 'nasi', 'nasz', 'nasza', 'nasze', 'naszego', 'naszych', 'natomiast', 'natychmiast', 'nawet', 'nią', 'nic', 'nich', 'nie', 'niech', 'niego', 'niej', 'niemu', 'nigdy', 'nim', 'nimi', 'niż', 'no', 'o', 'obok', 'od', 'około', 'on', 'ona', 'one', 'oni', 'ono', 'oraz', 'oto', 'owszem', 'pan', 'pana', 'pani', 'po', 'pod', 'podczas', 'pomimo', 'ponad', 'ponieważ', 'powinien', 'powinna', 'powinni', 'powinno', 'poza', 'prawie', 'przecież', 'przed', 'przede', 'przedtem', 'przez', 'przy', 'roku', 'również', 'sama', 'są', 'się', 'skąd', 'sobie', 'sobą', 'sposób', 'swoje', 'ta', 'tak', 'taka', 'taki', 'takie', 'także', 'tam', 'te', 'tego', 'tej', 'temu', 'ten', 'teraz', 'też', 'to', 'tobą', 'tobie', 'toteż', 'trzeba', 'tu', 'tutaj', 'twoi', 'twoim', 'twoja', 'twoje', 'twym', 'twój', 'ty', 'tych', 'tylko', 'tym', 'u', 'w', 'wam', 'wami', 'was', 'wasz', 'wasza', 'wasze', 'we', 'według', 'wiele', 'wielu', 'więc', 'więcej', 'wszyscy', 'wszystkich', 'wszystkie', 'wszystkim', 'wszystko', 'wtedy', 'wy', 'właśnie', 'z', 'za', 'zapewne', 'zawsze', 'ze', 'zł', 'znowu', 'znów', 'został', 'żaden', 'żadna', 'żadne', 'żadnych', 'że', 'żeby']\n",
    "\n",
    "X = df[['description','name','place_name_std','types']]\n",
    "y = df['tagname']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify = y)\n",
    "\n",
    "alpha=0.1\n",
    "max_features=500\n",
    "\n",
    "clf_desc = Pipeline([('sel', ColumnSelector('description')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_name = Pipeline([('sel', ColumnSelector('name')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_place = Pipeline([('sel', ColumnSelector('place_name_std')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_types = Pipeline([('sel', ColumnSelector('types')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('desc', clf_desc), \n",
    "                                    ('name', clf_name), \n",
    "                                    ('place', clf_place),\n",
    "                                    ('types', clf_types)],\n",
    "                                    voting='soft',\n",
    "                                    weights=[1,1,1,1])\n",
    "eclf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "predicted = eclf.predict(X_test)\n",
    "\n",
    "conf_arr = confusion_matrix(y_test, predicted, labels=eclf.classes_.tolist())\n",
    "\n",
    "plot_confusion_matrix(conf_arr, classes=eclf.classes_.tolist(),\n",
    "                      title='Confusion matrix, without normalization', normalize=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf_1 = eclf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Budowa modelu do określania typu wydarzeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = events_tagged[events_tagged['category'] == 'TYP WYDARZENIA'][['tagname','description','name','place_name_std', 'types']]\n",
    "df = df.groupby('tagname').filter(lambda x: len(x) > 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "stop_words = ['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'ależ', 'ani', 'aż', 'bardziej', 'bardzo', 'bo', 'bowiem', 'by', 'byli', 'bynajmniej', 'być', 'był', 'była', 'było', 'były', 'będzie', 'będą', 'cali', 'cała', 'cały', 'ci', 'cię', 'ciebie', 'co', 'cokolwiek', 'coś', 'czasami', 'czasem', 'czemu', 'czy', 'czyli', 'daleko', 'dla', 'dlaczego', 'dlatego', 'do', 'dobrze', 'dokąd', 'dość', 'dużo', 'dwa', 'dwaj', 'dwie', 'dwoje', 'dziś', 'dzisiaj', 'gdy', 'gdyby', 'gdyż', 'gdzie', 'gdziekolwiek', 'gdzieś', 'i', 'ich', 'ile', 'im', 'inna', 'inne', 'inny', 'innych', 'iż', 'ja', 'ją', 'jak', 'jaka', 'jakaś', 'jakby', 'jaki', 'jakichś', 'jakie', 'jakiś', 'jakiż', 'jakkolwiek', 'jako', 'jakoś', 'je', 'jeden', 'jedna', 'jedno', 'jednak', 'jednakże', 'jego', 'jej', 'jemu', 'jest', 'jestem', 'jeszcze', 'jeśli', 'jeżeli', 'już', 'ją', 'każdy', 'kiedy', 'kilka', 'kimś', 'kto', 'ktokolwiek', 'ktoś', 'która', 'które', 'którego', 'której', 'który', 'których', 'którym', 'którzy', 'ku', 'lat', 'lecz', 'lub', 'ma', 'mają', 'mało', 'mam', 'mi', 'mimo', 'między', 'mną', 'mnie', 'mogą', 'moi', 'moim', 'moja', 'moje', 'może', 'możliwe', 'można', 'mój', 'mu', 'musi', 'my', 'na', 'nad', 'nam', 'nami', 'nas', 'nasi', 'nasz', 'nasza', 'nasze', 'naszego', 'naszych', 'natomiast', 'natychmiast', 'nawet', 'nią', 'nic', 'nich', 'nie', 'niech', 'niego', 'niej', 'niemu', 'nigdy', 'nim', 'nimi', 'niż', 'no', 'o', 'obok', 'od', 'około', 'on', 'ona', 'one', 'oni', 'ono', 'oraz', 'oto', 'owszem', 'pan', 'pana', 'pani', 'po', 'pod', 'podczas', 'pomimo', 'ponad', 'ponieważ', 'powinien', 'powinna', 'powinni', 'powinno', 'poza', 'prawie', 'przecież', 'przed', 'przede', 'przedtem', 'przez', 'przy', 'roku', 'również', 'sama', 'są', 'się', 'skąd', 'sobie', 'sobą', 'sposób', 'swoje', 'ta', 'tak', 'taka', 'taki', 'takie', 'także', 'tam', 'te', 'tego', 'tej', 'temu', 'ten', 'teraz', 'też', 'to', 'tobą', 'tobie', 'toteż', 'trzeba', 'tu', 'tutaj', 'twoi', 'twoim', 'twoja', 'twoje', 'twym', 'twój', 'ty', 'tych', 'tylko', 'tym', 'u', 'w', 'wam', 'wami', 'was', 'wasz', 'wasza', 'wasze', 'we', 'według', 'wiele', 'wielu', 'więc', 'więcej', 'wszyscy', 'wszystkich', 'wszystkie', 'wszystkim', 'wszystko', 'wtedy', 'wy', 'właśnie', 'z', 'za', 'zapewne', 'zawsze', 'ze', 'zł', 'znowu', 'znów', 'został', 'żaden', 'żadna', 'żadne', 'żadnych', 'że', 'żeby']\n",
    "\n",
    "\n",
    "df2 = df\n",
    "X = df2[['description','name','place_name_std', 'types']]\n",
    "y = df2['tagname']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify = y)\n",
    "\n",
    "alpha=0.1\n",
    "max_features=500\n",
    "\n",
    "clf_desc = Pipeline([('sel', ColumnSelector('description')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_name = Pipeline([('sel', ColumnSelector('name')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_place = Pipeline([('sel', ColumnSelector('place_name_std')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "clf_types = Pipeline([('sel', ColumnSelector('types')),\n",
    "                     ('tfidf', TfidfVectorizer(stop_words=stop_words, use_idf=True, ngram_range=(1,1), max_features=max_features)),\n",
    "                     ('clf', MultinomialNB(alpha=alpha, fit_prior=False))])\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('desc', clf_desc), \n",
    "                                    ('name', clf_name), \n",
    "                                    ('place', clf_place),\n",
    "                                    ('types', clf_types)],\n",
    "                                    voting='soft',\n",
    "                                    weights=[1,1,1,1])\n",
    "\n",
    "eclf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "predicted = eclf.predict(X_test)\n",
    "\n",
    "conf_arr = confusion_matrix(y_test, predicted, labels=eclf.classes_.tolist())\n",
    "\n",
    "plot_confusion_matrix(conf_arr, classes=eclf.classes_.tolist(),\n",
    "                      title='Confusion matrix, without normalization', normalize=True, size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf_2 = eclf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predykcje dla wszystkich wydarzeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = data.name\\\n",
    ".mask(pd.isnull, data.name_ss)\\\n",
    ".mask(pd.isnull, data.name_cjg)\\\n",
    ".mask(pd.isnull, data.name_sk)\\\n",
    ".mask(pd.isnull, data.name_um)\n",
    "\n",
    "place_name = data.place_name\\\n",
    ".mask(pd.isnull, data.place_name_ss)\\\n",
    ".mask(pd.isnull, data.place_name_cjg)\\\n",
    ".mask(pd.isnull, data.place_name_sk)\\\n",
    ".mask(pd.isnull, data.place_name_um)\n",
    "\n",
    "description = data.description\\\n",
    ".mask(pd.isnull, data.description_ss)\\\n",
    ".mask(pd.isnull, data.description_cjg)\\\n",
    ".mask(pd.isnull, data.description_sk)\\\n",
    ".mask(pd.isnull, data.description_um)\n",
    "\n",
    "types = data['types'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_space = eclf_1.predict(pd.DataFrame({'description': description, 'name': name, 'place_name_std': place_name, 'types': types}))\n",
    "event_type = eclf_2.predict(pd.DataFrame({'description': description, 'name': name, 'place_name_std': place_name, 'types': types}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['event_space'] = event_space\n",
    "data['event_type'] = event_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializacja modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(eclf_1, '../models/events_space.pkl')\n",
    "joblib.dump(eclf_2, '../models/events_type.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zapisanie do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../output/events_database.csv')\n",
    "joblib.dump(data, '../pickles/events_database.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
